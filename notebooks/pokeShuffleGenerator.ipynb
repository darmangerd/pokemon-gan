{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torchvision.utils as vutils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = \"v1.0\"\n",
    "PATH = \"datas/shuffle/\"\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is very small, we need to augment it via rotating, flipping horizontally and changing very slightly the color of each pokemon.\n",
    "\n",
    "Normalize the data between [-1, 1], rezise images to the size we need for the model and transform data into tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset\n",
    "pokemon_dataset = datasets.ImageFolder(PATH, transform=T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])) # normalize to [-1, 1]\n",
    "# hue dataset(changing colors slightly)\n",
    "pokemon_hue_dataset = datasets.ImageFolder(PATH, transform=T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.ColorJitter(hue=0.5),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "# flipping horizontally dataset (mirror)\n",
    "pokemon_flip_dataset = datasets.ImageFolder(PATH, transform=T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(p=1.0),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "# rotating dataset (rotate)\n",
    "pokemon_rotate_dataset = datasets.ImageFolder(PATH, transform=T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.CenterCrop(IMAGE_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.RandomRotation(degrees=7),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "dataset_list = [pokemon_dataset, pokemon_rotate_dataset, pokemon_hue_dataset, pokemon_flip_dataset]\n",
    "dataset = ConcatDataset(dataset_list)\n",
    "dataloader = DataLoader(dataset, BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5001 # number of times all the batches passes through the models\n",
    "LR_DESC = 0.0001 # learning rate for discriminator\n",
    "LR_GEN = 0.0002 # learning rate for generator\n",
    "BETA1 = 0.5 # Adam optimizer BETA1 parameter\n",
    "GPU_COUNT = 1 # number of GPUs\n",
    "LATENT_VECTOR_DIM = 16 # latent vector dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choosed a 128x128 model because 256x256 wasn't working properly and 128x128 prompted correct pokemon with more data than 64x64 and quicker than 256x256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator model tries to predict if  the input(image) is a fake or not.\n",
    "\n",
    "With convolution, we reduce the size of the image to a single 1x1x1.\n",
    "\n",
    "LeakyReLu slope set to 0.2 (advised from papers on how to enhance gan).\n",
    "\n",
    "Test with dropout(0.5) didn't worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 128x128x3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_128(nn.Module):\n",
    "    def __init__(self, GPU_COUNT):\n",
    "        super(Discriminator_128, self).__init__()\n",
    "        self.GPU_COUNT = GPU_COUNT\n",
    "        self.main = nn.Sequential(\n",
    "            # 128 x 128 x 3\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1, bias=False), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # 1 x 1 x 1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the generator model generate fake pokemon to pass in the discriminator.\n",
    "\n",
    "It tries to generate fake pokemon that the discriminator thinks is real ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 128x128x3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_128(nn.Module):\n",
    "    def __init__(self, GPU_COUNT):\n",
    "        super(Generator_128, self).__init__()\n",
    "        self.GPU_COUNT = GPU_COUNT\n",
    "        self.main = nn.Sequential(\n",
    "            # LATENT_VECTOR_DIM x 1 x 1\n",
    "            nn.ConvTranspose2d(LATENT_VECTOR_DIM, 1024, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128,64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64,3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # 128 x 128 x 3\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights need to be set according to a normal function with 0 mean and 0.02 standard deviation.\n",
    "\n",
    "Spectral initialization is another way to initialize that could have beend done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We configure the gpu to be used instead of the cpu by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and GPU_COUNT > 0) else \"cpu\")\n",
    "\n",
    "nn_generator = Generator_128(GPU_COUNT).to(device)\n",
    "\n",
    "nn_generator.apply(weights_init)\n",
    "\n",
    "nn_discriminator = Discriminator_128(GPU_COUNT).to(device)\n",
    "\n",
    "nn_discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the learning rate of the discriminator to be lower than the generator to prevent the discriminator from overpowering the generator.\n",
    "\n",
    "We change real label to 0 and fake label to 1(should improve performance).\n",
    "\n",
    "By making fake label 0.9 instead of 0.9 we prevent the discriminator from being overconfident.\n",
    "\n",
    "We could have used SGD instead of adam for the discriminator, but it performed poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "criterion = nn.BCELoss() # measures the cross entropy between the target and the input probabilities.\n",
    "\n",
    "# We will use the same batch of latent vectors to see how the generator output evolves during training\n",
    "fixed_noise = torch.randn(64, LATENT_VECTOR_DIM, 1, 1, device=device)\n",
    "\n",
    "\n",
    "real_label = 0. # changed from 1. to 0 (prescribed in guides).\n",
    "fake_label = 0.9 # Smoothing label from 1 to 0.9 (to prevent overconfidence).\n",
    "\n",
    "# Setup Adam optimizers for both Descriminator and Generator\n",
    "disc_opt = optim.Adam(nn_discriminator.parameters(), lr=LR_DESC, betas=(BETA1, 0.999))\n",
    "gen_opt = optim.Adam(nn_generator.parameters(), lr=LR_GEN, betas=(BETA1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = 0 # snapshot image\n",
    "\n",
    "# losses for plotting\n",
    "generator_losses = []\n",
    "discriminator_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create noisy labels we flip labels at random(5 percent per batch).\n",
    "\n",
    "We save pics each 20 epochs and save the generator model each 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        nn_discriminator.zero_grad() # set gradients to zero\n",
    "        real_cpu = batch[0].to(device) \n",
    "        cpu_batch_size = real_cpu.size(0)\n",
    "        # 0.05 chance to flip labels to create noise (for better performance)\n",
    "        if random.random() < 0.05:\n",
    "            label = torch.full((cpu_batch_size,), fake_label, device=device)\n",
    "        else:\n",
    "            label = torch.full((cpu_batch_size,), real_label, device=device)\n",
    "        output = nn_discriminator(real_cpu).view(-1)\n",
    "        disc_error_real = criterion(output, label)\n",
    "        disc_error_real.backward()\n",
    "        noise = torch.randn(cpu_batch_size, LATENT_VECTOR_DIM, 1, 1, device=device) # latent vectors for generator\n",
    "        generated_pokemon = nn_generator(noise) # generate new pokemon\n",
    "        # 0.05 chance to flip labels to create noise (for better performance)\n",
    "        if random.random() < 0.05:\n",
    "            label.fill_(real_label)\n",
    "        else:\n",
    "            label.fill_(fake_label)\n",
    "        output = nn_discriminator(generated_pokemon.detach()).view(-1)\n",
    "        disc_error_fake = criterion(output, label)\n",
    "        disc_error_fake.backward()\n",
    "        disc_error_total = disc_error_real + disc_error_fake\n",
    "        disc_opt.step() # update discriminator weights\n",
    "        nn_generator.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = nn_discriminator(generated_pokemon).view(-1)\n",
    "        generator_error = criterion(output, label)\n",
    "        generator_error.backward()\n",
    "        gen_opt.step() # update generator weights\n",
    "        # print statistics\n",
    "        if i % len(dataloader) == 0:\n",
    "            print(\"[\" + str(epoch) + \"] + losses D: \" + str(disc_error_total.item()) + \" G:\" + str(generator_error.item()))\n",
    "        # add losses to list for plotting\n",
    "        generator_losses.append(generator_error.item())\n",
    "        discriminator_losses.append(disc_error_total.item())\n",
    "    # do checkpointing for every 20 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        with torch.no_grad():\n",
    "            generated_pokemon = nn_generator(fixed_noise).detach().cpu()\n",
    "        snapshot = vutils.make_grid(generated_pokemon, padding=2, normalize=True)\n",
    "        transform = T.ToPILImage()\n",
    "        img = transform(snapshot)\n",
    "        img.save(\"epochs_image/pokemon-\" + str(epoch) + str(TITLE) + \".jpg\")\n",
    "    # save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(nn_generator.state_dict(), \"generator_models/generator_epoch_\"+str(epoch)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(generator_losses,label=\"G\")\n",
    "plt.plot(discriminator_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"logs/loss\" + TITLE + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gif of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/57751793\n",
    "\n",
    "# filepaths\n",
    "fp_in = ( \"epochs_image/*.jpg\")\n",
    "fp_out = \"gan_training.gif\"\n",
    "\n",
    "# https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#gif\n",
    "imgs = (Image.open(f) for f in sorted(glob.glob(fp_in)))\n",
    "img = next(imgs)  # extract first image from iterator\n",
    "img.save(fp=fp_out, format='GIF', append_images=imgs,\n",
    "         save_all=True, duration=200, loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_gen = Generator_128(0)\n",
    "trained_gen.load_state_dict(torch.load(\"generator_models/generator_epoch_1000.h5\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(seed, pokemon_count):\n",
    "    torch.manual_seed(seed)\n",
    "    z = torch.randn(pokemon_count, LATENT_VECTOR_DIM, 1, 1)\n",
    "    punks = trained_gen(z)\n",
    "    save_image(punks, \"pokemon.png\", normalize=True)\n",
    "    return 'pokemon.png'\n",
    "\n",
    "gr.Interface(\n",
    "    predict,\n",
    "    inputs=[\n",
    "        gr.Slider(0, 1000, label='Seed', default=42),\n",
    "        gr.Slider(1, 8, label='Number of pokemon', step=1, default=10),\n",
    "    ],\n",
    "    outputs=\"image\",\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generated pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3abe0725108343d498cec85e5635da12bd51520d89c53b1b7cf044ebf762d142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
